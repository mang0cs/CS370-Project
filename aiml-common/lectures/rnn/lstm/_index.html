
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>The Long Short-Term Memory (LSTM) Cell Architecture &#8212; Introduction to Artificial Intelligence</title>
    
  <link href="../../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="canonical" href="https://pantelis.github.io/artificial-intelligence/aiml-common/lectures/rnn/lstm/_index.html" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Introduction to NLP" href="../../nlp/nlp-intro/_index.html" />
    <link rel="prev" title="Processing Sequences Using RNN" href="../15_processing_sequences_using_rnns_and_cnns.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Artificial Intelligence</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Syllabus
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../syllabus/_index.html">
   Syllabus
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to AI
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../ai-intro/course-introduction/_index.html">
   Course Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ai-intro/data-science-360/_index.html">
   Data Science 360
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ai-intro/systems-approach/_index.html">
   The four approaches towards AI
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ai-intro/agents/_index.html">
   Agent-Environment Interface
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ai-intro/pipelines/_index.html">
   Pipelines
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../uber-ml-arch-case-study/_index.html">
     A Case Study of an ML Architecture - Uber
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ai-intro/pipelines/02_end_to_end_machine_learning_project.html">
     Setup
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  The Learning Problem
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../learning-problem/_index.html">
   The Learning Problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../regression/linear-regression/_index.html">
   Linear Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../optimization/sgd/_index.html">
   Stochastic Gradient Descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../entropy/_index.html">
   Entropy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../optimization/maximum-likelihood/_index.html">
   Maximum Likelihood (ML) Estimation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../pgm/bayesian-inference/_index.html">
   Bayesian Inference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../pgm/bayesian-coin/_index.html">
     Bayesian Coin Flipping
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../classification/classification-intro/_index.html">
   Introduction to Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../classification/logistic-regression/_index.html">
   Logistic Regression
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Deep Neural Networks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../classification/perceptron/_index.html">
   The Neuron (Perceptron)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../dnn/dnn-intro/_index.html">
   Deep Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../dnn/backprop-intro/_index.html">
   Introduction to Backpropagation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../dnn/backprop-dnn/_index.html">
   Backpropagation in Deep Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../optimization/regularization/_index.html">
   Regularization in Deep Neural Networks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Convolutional Neural Networks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../cnn/cnn-intro/_index.html">
   Introduction to Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cnn/cnn-layers/_index.html">
   CNN Architectures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cnn/cnn-example-architectures/_index.html">
   CNN Example Architectures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cnn/cnn-example-architectures/using_convnets_with_small_datasets.html">
   Using convnets with small datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cnn/cnn-explainers/_index.html">
   CNN Explainers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../transfer-learning/transfer-learning-introduction.html">
   Introduction to Transfer Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../transfer-learning/transfer_learning_tutorial.html">
   Transfer Learning for Computer Vision Tutorial
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Scene Understanding
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../scene-understanding/scene-understanding-intro/_index.html">
   Introduction to Scene Understanding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../scene-understanding/feature-extraction-resnet/_index.html">
   Feature Extraction via Residual Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../scene-understanding/object-detection/_index.html">
   Object Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../scene-understanding/detection-segmentation-metrics/_index.html">
   Object Detection and Semantic Segmentation Metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../scene-understanding/rcnn/_index.html">
   Region-CNN (RCNN) Object Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../scene-understanding/faster-rcnn/_index.html">
   Faster RCNN Object Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../scene-understanding/object-detection/detection-segmentation-workshop/_index.html">
   Object Detection and Semantic Segmentation Workshop
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Probabilistic Reasoning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../pgm/pgm-intro/_index.html">
   Introduction to Probabilistic Reasoning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pgm/recursive-state-estimation/_index.html">
   Recursive State Estimation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pgm/bayesian-filter-workshop/_index.html">
   Bayesian Filter Workshop
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pgm/hmm-localization/_index.html">
   Localization and Tracking
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pgm/kalman-workshop/_index.html">
   Kalman Filter Workshop
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Logical Reasoning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../logical-reasoning/automated-reasoning/_index.html">
   Automated Reasoning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../logical-reasoning/propositional-logic/_index.html">
   World Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../logical-reasoning/logical-agents/_index.html">
   Logical Agents
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Planning without Interactions
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../planning/_index.html">
   Planning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../autonomous-cars/_index.html">
   Autonomous Agents
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../autonomous-cars/imitation-learning/_index.html">
   Imitation Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../planning/classical-planning/_index.html">
   Classical Planning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../planning/search/_index.html">
   Planning with Search
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../planning/search/forward-search/_index.html">
   Forward Search Algorithms
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../planning/search/a-star/_index.html">
   The A* Algorithm
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Markov Decision Processes
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../mdp/_index.html">
   Markov Decision Processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../mdp/mdp-intro/_index.html">
   Introduction to MDP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../mdp/bellman-expectation-backup/_index.html">
   Bellman Expectation Backup
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../mdp/bellman-optimality-backup/_index.html">
   Bellman Optimality Backup
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Dynamic Programming Algorithms
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../mdp/mdp-dp-algorithms/policy-iteration/_index.html">
   Dynamic Programming Algorithms - Policy Iteration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../mdp/mdp-dp-algorithms/policy-evaluation/_index.html">
   Policy Evaluation (Prediction)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../mdp/mdp-dp-algorithms/policy-improvement/_index.html">
   Policy Improvement (Control)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../mdp/mdp-dp-algorithms/value-iteration/_index.html">
   Dynamic Programming Algorithms - Value Iteration
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MDP Lab
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../mdp/mdp-lab/recycling-robot/_index.html">
   Finding the optimal policy of a recycling robot.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../mdp/mdp-lab/yield-management-capacity-control/_index.html">
   Optimal Capacity Control
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reinforcement Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../reinforcement-learning/_index.html">
   Reinforcement Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../reinforcement-learning/prediction/monte-carlo.html">
   Monte-Carlo Prediction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../reinforcement-learning/prediction/temporal-difference.html">
   Temporal Difference (TD) Prediction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../reinforcement-learning/control/_index.html">
   Model-free Control
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../reinforcement-learning/generalized-policy-iteration/_index.html">
   Generalized Policy Iteration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../reinforcement-learning/control/sarsa/_index.html">
   The SARSA Algorithm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../reinforcement-learning/reinforce/_index.html">
   The REINFORCE Algorithm
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Sequences and RNNs
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction/_index.html">
   Introduction to Recurrent Neural Networks (RNN)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../simple-rnn/_index.html">
   Simple RNN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../15_processing_sequences_using_rnns_and_cnns.html">
   Processing Sequences Using RNN
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   The Long Short-Term Memory (LSTM) Cell Architecture
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Natural Language Processing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/nlp-intro/_index.html">
   Introduction to NLP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/word2vec/_index.html">
   Word2Vec Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/rnn-language-models/_index.html">
   RNN Language Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/nmt/_index.html">
   Neural Machine Translation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/nmt-metrics/_index.html">
   NMT Metrics - BLEU
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/attention/_index.html">
   Attention in NMT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/transformers/_index.html">
   Transformers Workshop
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Math Background
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ml-math/_index.html">
   Math for ML
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-math/probability/_index.html">
     Probability Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../linear-algebra/_index.html">
     Linear Algebra for Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-math/calculus/_index.html">
     Calculus
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../resources/environment/_index.html">
   Your Programming Environment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../python/_index.html">
   Learn Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../runbook.html">
   Executable Content Runbook
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Assignments &amp; Projects
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../assignments/probability/probability-assignment-2/probability-assignment-2.html">
   Probability Assigmment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../assignments/mle/mle_exponential_linear_regression.html">
   Maximum Likelihood Parameter Estimation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../assignments/object-tracking/_index.html">
   Multiple Object Tracking
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../projects/visual-search/_index.html">
   Reverse Visual Search
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../projects/_index.html">
   Course Project Guidelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../projects/container-terminal-automation/container-terminal-automation.html">
   Omniverse Container Terminal Oracle Network
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../../_sources/aiml-common/lectures/rnn/lstm/_index.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/pantelis/artificial-intelligence"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/pantelis/artificial-intelligence/issues/new?title=Issue%20on%20page%20%2Faiml-common/lectures/rnn/lstm/_index.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#input-gate">
   Input Gate
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#output-gate">
   Output Gate
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-cell-state-and-the-forget-gate">
   The Cell State and the Forget Gate
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lstm-workshop">
   LSTM Workshop
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#additional-resources">
   Additional Resources
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>The Long Short-Term Memory (LSTM) Cell Architecture</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#input-gate">
   Input Gate
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#output-gate">
   Output Gate
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-cell-state-and-the-forget-gate">
   The Cell State and the Forget Gate
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lstm-workshop">
   LSTM Workshop
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#additional-resources">
   Additional Resources
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="the-long-short-term-memory-lstm-cell-architecture">
<h1>The Long Short-Term Memory (LSTM) Cell Architecture<a class="headerlink" href="#the-long-short-term-memory-lstm-cell-architecture" title="Permalink to this headline">¶</a></h1>
<p>In the simple RNN we have seen the problem of exploding or vanishing gradients when <a class="reference external" href="http://ai.dinfo.unifi.it/paolo//ps/tnn-94-gradient.pdf">the span of back-propagation is large</a> (large <span class="math notranslate nohighlight">\(\tau\)</span>). Using the conceptual IIR filter, that ultimately <em>integrates</em> the input signal, we have seen that in order to avoid an exploding or vanishing impulse response, we need to control <span class="math notranslate nohighlight">\(w\)</span>. This is exactly what is being done in evolutionary RNN architectures that we will treat in this section called <em>gated RNNs</em>. The best known gated RNN architecture is called the LSTM <em>cell</em> and in this case the weight <span class="math notranslate nohighlight">\(w\)</span> is not fixed but it is determined based on the input sequence <em>context</em>. The architecture is shown below.</p>
<p><img alt="lstm-cell" src="../../../../_images/rnn-LSTM.png" />
<em>LSTM architecture: It is divided into three areas: input (green), cell state (blue) and output (red). You can clearly see the outer (<span class="math notranslate nohighlight">\(\mathbf h_{t-1}\)</span> )and the inner (<span class="math notranslate nohighlight">\(\mathbf s_{t-1}\)</span>) recurrence loops.</em></p>
<p>Because we need to capture the input context that involve going back several time steps in the past, we introduce an <em>additional</em> inner recurrence loop that is effectively a variable length internal to the cell memory - we call this the <em>cell state</em>.  We employ another hidden unit called the <em>forget gate</em>  to learn the input context and the forgetting factor (equivalent to the <span class="math notranslate nohighlight">\(w\)</span> we have seen in the IIR filter) i.e. the extent that the cell forgets the previous hidden state. We employ a couple of other gates as well: the <em>input gate</em> and the <em>output gate</em> as shown in the diagram below.</p>
<p>In the following we are describing what each component is doing. Notation wise:</p>
<ol class="simple">
<li><p>We use two indices - <span class="math notranslate nohighlight">\(t\)</span> for the unfolding sequence index and <span class="math notranslate nohighlight">\(i\)</span> for the cell index <span class="math notranslate nohighlight">\(i\)</span> of the LSTM layer.</p></li>
<li><p>We also denote by <span class="math notranslate nohighlight">\(\mathbf A(i,:)\)</span>,  the i-th row of the matrix <span class="math notranslate nohighlight">\(\mathbf A\)</span>.</p></li>
</ol>
<p>Notice that if you make the output factors of input and output gates equal to 1.0 and the forgetting factor equal to 0.0, we are back to the simple RNN architecture.</p>
<div class="section" id="input-gate">
<h2>Input Gate<a class="headerlink" href="#input-gate" title="Permalink to this headline">¶</a></h2>
<p>The input gate <em>protects the cell state</em> contents from perturbations by irrelevant to the context inputs. Quantitatively,  input gate calculates the factor,</p>
<div class="math notranslate nohighlight">
\[g_t(i) =\sigma \Big( \mathbf W_g(i,:) \mathbf h_{t-1}^i + \mathbf U_g(i,:) \mathbf x_t^i + \mathbf b_g^i \Big) \]</div>
<p>The gate uses the sigmoid function to produce a factor between 0 and 1 for <em>each</em> of the cells of the LSTM layer - each cell is indexed by <span class="math notranslate nohighlight">\(i\)</span>. This factor is applied to the <span class="math notranslate nohighlight">\(i\)</span>-th cell’s input that is the combination of a function  of the previous hidden state represented by the dot product <span class="math notranslate nohighlight">\(\mathbf W_g(i,:) \mathbf h_{t-1}^i\)</span>  and a function of the current input, represented by the dot product <span class="math notranslate nohighlight">\(\mathbf U_g(i,:) \mathbf x_t^i\)</span>.</p>
</div>
<div class="section" id="output-gate">
<h2>Output Gate<a class="headerlink" href="#output-gate" title="Permalink to this headline">¶</a></h2>
<p>The output gate <em>protects the subsequent cells</em> from perturbations by irrelevant to their context cell state. Quantitatively,</p>
<div class="math notranslate nohighlight">
\[h_t^i = q_t^i \tanh(s_t^i)\]</div>
<p>where <span class="math notranslate nohighlight">\(q_t^i\)</span> is the output factor</p>
<div class="math notranslate nohighlight">
\[q_t{(i)} =\sigma \Big( \mathbf W_o(i,:) \mathbf h_{t-1}^i + \mathbf U_o(i,:) \mathbf x_t^i + \mathbf b_o^i \Big) \]</div>
</div>
<div class="section" id="the-cell-state-and-the-forget-gate">
<h2>The Cell State and the Forget Gate<a class="headerlink" href="#the-cell-state-and-the-forget-gate" title="Permalink to this headline">¶</a></h2>
<p>This is the heart of the LSTM cell, the cell state is the new memory that is introduced by LSTM - all the earlier factors are used to preserve it as long as it is needed by the use case.</p>
<div class="math notranslate nohighlight">
\[s_t^i = f_t^i s_{t-1}^i + g_t^i \sigma \Big( \mathbf W(i,:) \mathbf h_{t-1}^i + \mathbf U(i,:) \mathbf x_t^i + \mathbf b^i \Big)\]</div>
<p>The parameters <span class="math notranslate nohighlight">\(\theta_{in} = \\{  \mathbf W, \mathbf U, \mathbf b \\}\)</span>  are the recurrent weights, input weights and bias respectively at the input of the i-th LSTM cell. Please note that in the above equation some authors use a <span class="math notranslate nohighlight">\(\tanh\)</span> non-linearity to transform the input instead of sigmoid.</p>
<p>The forget gate calculates the forgetting factor,</p>
<div class="math notranslate nohighlight">
\[f_t^i =\sigma \Big( \mathbf W_f(i,:) \mathbf h_{t-1}^i + \mathbf U_f(i,:) \mathbf x_t^i + \mathbf b_f^i \Big) \]</div>
<p>Similar to the input gate, this factor determines the amount of the earlier cell state that is needed to be preserved.</p>
<p>Closing, you can expect backpropagation to work similarly to simple RNN case <a class="reference external" href="https://christinakouridi.blog/2019/06/19/backpropagation-lstm/">albeit with more complicated expressions</a>. In the LSTM workshop that follows you will have the opportunity to look at an LSTM training from scratch.</p>
<p>Hyperparameter optimization for LSTMs is addressed more formally <a class="reference external" href="https://arxiv.org/pdf/1503.04069v1.pdf">“LSTM: A Search Space Odyssey”</a></p>
</div>
<div class="section" id="lstm-workshop">
<h2>LSTM Workshop<a class="headerlink" href="#lstm-workshop" title="Permalink to this headline">¶</a></h2>
<p>Please go through <a class="reference external" href="https://christinakouridi.blog/2019/06/20/vanilla-lstm-numpy/">this</a> from scratch implementation of LSTM. Note that the notation is different than in your notes and follows <a class="reference external" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">this well known blog post</a>.</p>
</div>
<div class="section" id="additional-resources">
<h2>Additional Resources<a class="headerlink" href="#additional-resources" title="Permalink to this headline">¶</a></h2>
<p>Additional tutorial resources on LSTMs can be found here:</p>
<ol class="simple">
<li><p><a class="reference external" href="https://arxiv.org/pdf/1506.00019.pdf">A Critical Review of Recurrent Neural Networks for Sequence Learning</a></p></li>
<li><p><a class="reference external" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs">Understanding LSTMs</a></p></li>
<li><p><a class="reference external" href="https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21">Illustrated guide to LSTMs</a></p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=WCUNPb-5EYI">Simplest possible LSTM explanation video</a></p></li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./aiml-common/lectures/rnn/lstm"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../15_processing_sequences_using_rnns_and_cnns.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Processing Sequences Using RNN</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../../nlp/nlp-intro/_index.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Introduction to NLP</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Pantelis Monogioudis, Ph.D<br/>
    
        &copy; Copyright 2022.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>