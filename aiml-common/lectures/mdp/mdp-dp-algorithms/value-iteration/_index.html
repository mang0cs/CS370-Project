
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Dynamic Programming Algorithms - Value Iteration &#8212; Introduction to Artificial Intelligence</title>
    
  <link href="../../../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../../../../" id="documentation_options" src="../../../../../_static/documentation_options.js"></script>
    <script src="../../../../../_static/jquery.js"></script>
    <script src="../../../../../_static/underscore.js"></script>
    <script src="../../../../../_static/doctools.js"></script>
    <script src="../../../../../_static/clipboard.min.js"></script>
    <script src="../../../../../_static/copybutton.js"></script>
    <script src="../../../../../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="canonical" href="https://pantelis.github.io/artificial-intelligence/aiml-common/lectures/mdp/mdp-dp-algorithms/value-iteration/_index.html" />
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" />
    <link rel="next" title="Finding the optimal policy of a recycling robot." href="../../mdp-lab/recycling-robot/_index.html" />
    <link rel="prev" title="Policy Improvement (Control)" href="../policy-improvement/_index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Artificial Intelligence</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Syllabus
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../../syllabus/_index.html">
   Syllabus
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to AI
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ai-intro/course-introduction/_index.html">
   Course Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ai-intro/data-science-360/_index.html">
   Data Science 360
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ai-intro/systems-approach/_index.html">
   The four approaches towards AI
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ai-intro/agents/_index.html">
   Agent-Environment Interface
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ai-intro/pipelines/_index.html">
   Pipelines
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../uber-ml-arch-case-study/_index.html">
     A Case Study of an ML Architecture - Uber
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ai-intro/pipelines/02_end_to_end_machine_learning_project.html">
     Setup
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  The Learning Problem
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../learning-problem/_index.html">
   The Learning Problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../regression/linear-regression/_index.html">
   Linear Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../optimization/sgd/_index.html">
   Stochastic Gradient Descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../entropy/_index.html">
   Entropy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../optimization/maximum-likelihood/_index.html">
   Maximum Likelihood (ML) Estimation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../pgm/bayesian-inference/_index.html">
   Bayesian Inference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../pgm/bayesian-coin/_index.html">
     Bayesian Coin Flipping
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../classification/classification-intro/_index.html">
   Introduction to Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../classification/logistic-regression/_index.html">
   Logistic Regression
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Deep Neural Networks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../classification/perceptron/_index.html">
   The Neuron (Perceptron)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../dnn/dnn-intro/_index.html">
   Deep Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../dnn/backprop-intro/_index.html">
   Introduction to Backpropagation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../dnn/backprop-dnn/_index.html">
   Backpropagation in Deep Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../optimization/regularization/_index.html">
   Regularization in Deep Neural Networks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Convolutional Neural Networks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../cnn/cnn-intro/_index.html">
   Introduction to Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../cnn/cnn-layers/_index.html">
   CNN Architectures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../cnn/cnn-example-architectures/_index.html">
   CNN Example Architectures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../cnn/cnn-example-architectures/using_convnets_with_small_datasets.html">
   Using convnets with small datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../cnn/cnn-explainers/_index.html">
   CNN Explainers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../transfer-learning/transfer-learning-introduction.html">
   Introduction to Transfer Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../transfer-learning/transfer_learning_tutorial.html">
   Transfer Learning for Computer Vision Tutorial
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Scene Understanding
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../scene-understanding/scene-understanding-intro/_index.html">
   Introduction to Scene Understanding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../scene-understanding/feature-extraction-resnet/_index.html">
   Feature Extraction via Residual Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../scene-understanding/object-detection/_index.html">
   Object Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../scene-understanding/detection-segmentation-metrics/_index.html">
   Object Detection and Semantic Segmentation Metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../scene-understanding/rcnn/_index.html">
   Region-CNN (RCNN) Object Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../scene-understanding/faster-rcnn/_index.html">
   Faster RCNN Object Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../scene-understanding/object-detection/detection-segmentation-workshop/_index.html">
   Object Detection and Semantic Segmentation Workshop
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Probabilistic Reasoning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../pgm/pgm-intro/_index.html">
   Introduction to Probabilistic Reasoning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../pgm/recursive-state-estimation/_index.html">
   Recursive State Estimation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../pgm/bayesian-filter-workshop/_index.html">
   Bayesian Filter Workshop
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../pgm/hmm-localization/_index.html">
   Localization and Tracking
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../pgm/kalman-workshop/_index.html">
   Kalman Filter Workshop
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Logical Reasoning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../logical-reasoning/automated-reasoning/_index.html">
   Automated Reasoning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../logical-reasoning/propositional-logic/_index.html">
   World Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../logical-reasoning/logical-agents/_index.html">
   Logical Agents
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Planning without Interactions
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../planning/_index.html">
   Planning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../autonomous-cars/_index.html">
   Autonomous Agents
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../autonomous-cars/imitation-learning/_index.html">
   Imitation Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../planning/classical-planning/_index.html">
   Classical Planning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../planning/search/_index.html">
   Planning with Search
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../planning/search/forward-search/_index.html">
   Forward Search Algorithms
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../planning/search/a-star/_index.html">
   The A* Algorithm
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Markov Decision Processes
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../_index.html">
   Markov Decision Processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../mdp-intro/_index.html">
   Introduction to MDP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../bellman-expectation-backup/_index.html">
   Bellman Expectation Backup
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../bellman-optimality-backup/_index.html">
   Bellman Optimality Backup
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Dynamic Programming Algorithms
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../policy-iteration/_index.html">
   Dynamic Programming Algorithms - Policy Iteration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../policy-evaluation/_index.html">
   Policy Evaluation (Prediction)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../policy-improvement/_index.html">
   Policy Improvement (Control)
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Dynamic Programming Algorithms - Value Iteration
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MDP Lab
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../mdp-lab/recycling-robot/_index.html">
   Finding the optimal policy of a recycling robot.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../mdp-lab/yield-management-capacity-control/_index.html">
   Optimal Capacity Control
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reinforcement Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../reinforcement-learning/_index.html">
   Reinforcement Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../reinforcement-learning/generalized-policy-iteration/_index.html">
   Generalized Policy Iteration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../reinforcement-learning/prediction/_index.html">
   Model-free Prediction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../reinforcement-learning/control/_index.html">
   Model-free Control
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../reinforcement-learning/control/sarsa/_index.html">
   The SARSA Algorithm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../reinforcement-learning/reinforce/_index.html">
   The REINFORCE Algorithm
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Sequences and RNNs
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../rnn/introduction/_index.html">
   Introduction to Recurrent Neural Networks (RNN)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../rnn/simple-rnn/_index.html">
   Simple RNN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../rnn/15_processing_sequences_using_rnns_and_cnns.html">
   Processing Sequences Using RNN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../rnn/lstm/_index.html">
   The Long Short-Term Memory (LSTM) Cell Architecture
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Natural Language Processing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../nlp/nlp-intro/_index.html">
   Introduction to NLP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../nlp/word2vec/_index.html">
   Word2Vec Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../nlp/rnn-language-models/_index.html">
   RNN Language Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../nlp/nmt/_index.html">
   Neural Machine Translation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../nlp/nmt-metrics/_index.html">
   NMT Metrics - BLEU
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../nlp/attention/_index.html">
   Attention in NMT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../nlp/transformers/_index.html">
   Transformers Workshop
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Math Background
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-math/_index.html">
   Math for ML
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-math/probability/_index.html">
     Probability Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../linear-algebra/_index.html">
     Linear Algebra for Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-math/calculus/_index.html">
     Calculus
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../resources/environment/_index.html">
   Your Programming Environment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../python/_index.html">
   Learn Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../runbook.html">
   Executable Content Runbook
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Assignments &amp; Projects
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../assignments/probability/probability-assignment-2/probability-assignment-2.html">
   Probability Assigmment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../assignments/mle/mle_exponential_linear_regression.html">
   Maximum Likelihood Parameter Estimation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../assignments/object-tracking/_index.html">
   Multiple Object Tracking
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../projects/visual-search/_index.html">
   Reverse Visual Search
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../projects/_index.html">
   Course Project Guidelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../projects/container-terminal-automation/container-terminal-automation.html">
   Omniverse Container Terminal Oracle Network
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../../../_sources/aiml-common/lectures/mdp/mdp-dp-algorithms/value-iteration/_index.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/pantelis/artificial-intelligence"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/pantelis/artificial-intelligence/issues/new?title=Issue%20on%20page%20%2Faiml-common/lectures/mdp/mdp-dp-algorithms/value-iteration/_index.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#value-iteration-example">
   Value iteration example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#value-iteration-in-gridworld-example">
   Value Iteration in Gridworld Example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#value-iteration">
   Value Iteration
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#value-iteration-t-0">
     Value Iteration (t=0)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#value-iteration-t-1">
     Value Iteration (t=1)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#value-iteration-t-2">
     Value Iteration (t=2)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#value-iteration-convergence">
     Value Iteration - Convergence
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Dynamic Programming Algorithms - Value Iteration</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#value-iteration-example">
   Value iteration example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#value-iteration-in-gridworld-example">
   Value Iteration in Gridworld Example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#value-iteration">
   Value Iteration
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#value-iteration-t-0">
     Value Iteration (t=0)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#value-iteration-t-1">
     Value Iteration (t=1)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#value-iteration-t-2">
     Value Iteration (t=2)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#value-iteration-convergence">
     Value Iteration - Convergence
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="dynamic-programming-algorithms-value-iteration">
<h1>Dynamic Programming Algorithms - Value Iteration<a class="headerlink" href="#dynamic-programming-algorithms-value-iteration" title="Permalink to this headline">¶</a></h1>
<p>We already have seen that in the Gridworld example in the policy iteration section , we may not <em>need</em> to reach the optimal state value function <span class="math notranslate nohighlight">\(v_*(s)\)</span> to obtain an optimal policy to result. The value function for the <span class="math notranslate nohighlight">\(k=3\)</span> iteration results the same policy as the policy from a far more accurate value function (large k).</p>
<p>We can therefore stop early and taking the argument to the limit, do the policy improvement step in <em>each</em> iteration.  In this section we will look at an algorithm called value iteration that does that.</p>
<p><img alt="value-iteration-summary" src="../../../../../_images/value-iteration-summary.png" />
<em>Summary of Value Iteration</em></p>
<p>The basic principle behind value-iteration is the principle that underlines dynamic programming and is called the <em>principle of optimality</em> as applied to policies. According to this principle an <em>optimal</em> policy can be divided into two components.</p>
<ol class="simple">
<li><p>An optimal first action <span class="math notranslate nohighlight">\(a_*\)</span>.</p></li>
<li><p>An optimal policy from the successor state <span class="math notranslate nohighlight">\(s^\prime\)</span>.</p></li>
</ol>
<p>More formally, a policy <span class="math notranslate nohighlight">\(\pi(a|s)\)</span> achieves the optimal value from state <span class="math notranslate nohighlight">\(s\)</span>, <span class="math notranslate nohighlight">\(v_\pi(s) = v_*(s)\)</span> iff for any state <span class="math notranslate nohighlight">\(s^\prime\)</span> reachable from <span class="math notranslate nohighlight">\(s\)</span>, <span class="math notranslate nohighlight">\(v_\pi(s^\prime)=v_*(s)\)</span>.</p>
<p>Effectively this principle allows us to decompose the problem into two sub-problems with one of them being straightforward to determine and use the Bellman <strong>optimality equation</strong> that provides the one step backup induction at each iteration.</p>
<div class="math notranslate nohighlight">
\[v_*(s) = \max_a \left( \mathcal R_s^a + \gamma \sum_{s^\prime \in \mathcal S} \mathcal{P}^a_{ss^\prime} v_*(s^\prime) \right)\]</div>
<p>As an example if I want to move optimally towards a location in the room, I can make a optimal first step and at that point I can follow the optimal policy, that I was magically given, towards the desired final location. That optimal first step, think about making it by walking backwards from the goal. We start at the end of the problem where we know the final rewards and work backwards to all the states that connect to it in our look-ahead tree.</p>
<p><img alt="value-iteration-look-ahead-tree" src="../../../../../_images/value-iteration-look-ahead-tree.png" />
<em>One step look-ahead tree representation of value iteration algorithm</em></p>
<p>The “start from the end” intuition behind the equation is usually applied with no consideration as to if we are at the end or not. We just do the backup inductive step for each state.  In value iteration for synchronous backups, we start at <span class="math notranslate nohighlight">\(k=0\)</span> from the value function <span class="math notranslate nohighlight">\(v_0(s)=0.0\)</span> and at each iteration <span class="math notranslate nohighlight">\(k+1\)</span> for all states <span class="math notranslate nohighlight">\(s \in \mathcal{S}\)</span> we update the <span class="math notranslate nohighlight">\(v_{k+1}(s)\)</span> from <span class="math notranslate nohighlight">\(v_k(s)\)</span>. As the iterations progress, the value function will converge to <span class="math notranslate nohighlight">\(v_*\)</span>.</p>
<p>The equation of value iteration is taken straight out of the Bellman optimality equation, <strong>by turning the later into an update rule</strong>.</p>
<div class="math notranslate nohighlight">
\[v_{k+1}(s) = \max_a \left( \mathcal R_s^a + \gamma \sum_{s^\prime \in \mathcal S} \mathcal{P}^a_{ss^\prime} v_k(s^\prime) \right) \]</div>
<p>The value iteration can be written in a vector form as,</p>
<div class="math notranslate nohighlight">
\[\mathbf v_{k+1} = \max_a \left( \mathcal R^a + \gamma \mathcal P^a \mathbf v_k \right) \]</div>
<p>Notice that we are not building an explicit policy at every iteration and also, importantly, the intermediate value functions may <em>not</em> correspond to a feasible policy. Before going into a more elaborate example, we can go back to the same simple world we have looked at in the policy iteration section and focus only on the state-value calculation using the formula above.</p>
<p><img alt="gridworld-value-iteration" src="../../../../../_images/gridworld-value-iteration-value-only.png" />
<em>State values for an MDP with random policy (0.25 prob of taking any of the four available actions), <span class="math notranslate nohighlight">\(\gamma=1\)</span>, that rewards the agent with -1 at each transition except towards the goal states that are in the top left and bottom right corners</em></p>
<div class="section" id="value-iteration-example">
<h2>Value iteration example<a class="headerlink" href="#value-iteration-example" title="Permalink to this headline">¶</a></h2>
<p>In example world shown below (from <a class="reference external" href="http://i-systems.github.io/HSE545/iAI/AI/topics/05_MDP/11_MDP.html">here</a>)</p>
<p><img alt="gridworld" src="../../../../../_images/gridworld.png" />
<em>Gridworld to showcase the state-value calculation in Python code below. The states are numbered sequentially from top right.</em></p>
<p>we can calculate the state-value function its the vector form - the function in this world maps the state space to the 11th dim real vector space  <span class="math notranslate nohighlight">\(v(s): \mathcal S \rightarrow \mathbb R^{11}\)</span> aka the value function is a vector of size 11.</p>
<div class="math notranslate nohighlight">
\[\mathbf v_{k+1} = \max_a \left( \mathcal R^a + \gamma \mathcal P^a \mathbf v_k \right) \]</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Look at the backup tree above and the vector form Bellman equation to understand this code. </span>
<span class="c1"># Have them side by side while you are reading. </span>
<span class="c1"># Each of the 11 rows of the &quot;matrix&quot; P[s][a] has 4 tuples - one for each of the allowed actions. Each tuple / action is written in the format (probability, s&#39;) and is associated with the 3 possible next states that the agent may end up despite its intention to go to the desired state. The states are numbered sequentially from top left to bottom right. </span>

<span class="n">P</span> <span class="o">=</span> <span class="p">{</span>
 <span class="mi">0</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.9</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">1</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">4</span><span class="p">)],</span> <span class="mi">1</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">1</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">4</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">0</span><span class="p">)],</span> <span class="mi">2</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">4</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">1</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">0</span><span class="p">)],</span> <span class="mi">3</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.9</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">4</span><span class="p">)]},</span>
 <span class="mi">1</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">1</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">2</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">0</span><span class="p">)],</span> <span class="mi">1</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">2</span><span class="p">),(</span><span class="mf">0.2</span><span class="p">,</span><span class="mi">1</span><span class="p">)],</span> <span class="mi">2</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">1</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">2</span><span class="p">)],</span> <span class="mi">3</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mf">0.2</span><span class="p">,</span><span class="mi">1</span><span class="p">)]},</span>
 <span class="mi">2</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">2</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">3</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">1</span><span class="p">)],</span> <span class="mi">1</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">3</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">5</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">2</span><span class="p">)],</span> <span class="mi">2</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">5</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">1</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">3</span><span class="p">)],</span> <span class="mi">3</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">1</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">2</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">5</span><span class="p">)]},</span>
 <span class="mi">3</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.9</span><span class="p">,</span><span class="mi">3</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">2</span><span class="p">)],</span> <span class="mi">1</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.9</span><span class="p">,</span><span class="mi">3</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">6</span><span class="p">)],</span> <span class="mi">2</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">6</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">2</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">3</span><span class="p">)],</span> <span class="mi">3</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">2</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">3</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">6</span><span class="p">)]},</span>
 <span class="mi">4</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mf">0.2</span><span class="p">,</span><span class="mi">4</span><span class="p">)],</span> <span class="mi">1</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">4</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">7</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">0</span><span class="p">)],</span> <span class="mi">2</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">7</span><span class="p">),(</span><span class="mf">0.2</span><span class="p">,</span><span class="mi">4</span><span class="p">)],</span> <span class="mi">3</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">4</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">7</span><span class="p">)]},</span>
 <span class="mi">5</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">2</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">6</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">5</span><span class="p">)],</span> <span class="mi">1</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">6</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">9</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">2</span><span class="p">)],</span> <span class="mi">2</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">9</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">5</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">6</span><span class="p">)],</span> <span class="mi">3</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">5</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">2</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">9</span><span class="p">)]},</span>
 <span class="mi">6</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">3</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">6</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">5</span><span class="p">)],</span> <span class="mi">1</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">6</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">10</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">3</span><span class="p">)],</span> <span class="mi">2</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">10</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">5</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">6</span><span class="p">)],</span> <span class="mi">3</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">5</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">3</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">10</span><span class="p">)]},</span>
 <span class="mi">7</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">4</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">8</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">7</span><span class="p">)],</span> <span class="mi">1</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">8</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">7</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">4</span><span class="p">)],</span> <span class="mi">2</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.9</span><span class="p">,</span><span class="mi">7</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">8</span><span class="p">)],</span> <span class="mi">3</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.9</span><span class="p">,</span><span class="mi">7</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">4</span><span class="p">)]},</span>
 <span class="mi">8</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">8</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">9</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">7</span><span class="p">)],</span> <span class="mi">1</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">9</span><span class="p">),(</span><span class="mf">0.2</span><span class="p">,</span><span class="mi">8</span><span class="p">)],</span> <span class="mi">2</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">8</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">7</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">9</span><span class="p">)],</span> <span class="mi">3</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">7</span><span class="p">),(</span><span class="mf">0.2</span><span class="p">,</span><span class="mi">8</span><span class="p">)]},</span>
 <span class="mi">9</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">5</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">10</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">8</span><span class="p">)],</span> <span class="mi">1</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">9</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">9</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">5</span><span class="p">)],</span> <span class="mi">2</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">9</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">8</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">10</span><span class="p">)],</span> <span class="mi">3</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">8</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">5</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">9</span><span class="p">)]},</span>
 <span class="mi">10</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">6</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">10</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">9</span><span class="p">)],</span> <span class="mi">1</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.9</span><span class="p">,</span><span class="mi">10</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">6</span><span class="p">)],</span> <span class="mi">2</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.9</span><span class="p">,</span><span class="mi">10</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">9</span><span class="p">)],</span> <span class="mi">3</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">9</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">6</span><span class="p">),(</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">10</span><span class="p">)]}</span>
<span class="p">}</span>

<span class="n">R</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.9</span>

<span class="n">States</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="n">Actions</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span> <span class="c1"># [north, east, south, west]</span>

<span class="n">v</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">11</span>

<span class="c1"># value iteration</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">States</span><span class="p">:</span>
        <span class="c1"># trans[1] = s&#39;</span>
        <span class="c1"># trans[0] = P_ss&#39;</span>
        <span class="n">q_0</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">trans</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">v</span><span class="p">[</span><span class="n">trans</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="k">for</span> <span class="n">trans</span> <span class="ow">in</span> <span class="n">P</span><span class="p">[</span><span class="n">s</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">q_1</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">trans</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">v</span><span class="p">[</span><span class="n">trans</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="k">for</span> <span class="n">trans</span> <span class="ow">in</span> <span class="n">P</span><span class="p">[</span><span class="n">s</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">q_2</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">trans</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">v</span><span class="p">[</span><span class="n">trans</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="k">for</span> <span class="n">trans</span> <span class="ow">in</span> <span class="n">P</span><span class="p">[</span><span class="n">s</span><span class="p">][</span><span class="mi">2</span><span class="p">])</span>
        <span class="n">q_3</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">trans</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">v</span><span class="p">[</span><span class="n">trans</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="k">for</span> <span class="n">trans</span> <span class="ow">in</span> <span class="n">P</span><span class="p">[</span><span class="n">s</span><span class="p">][</span><span class="mi">3</span><span class="p">])</span>

        <span class="n">v</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">R</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">+</span> <span class="n">gamma</span><span class="o">*</span><span class="nb">max</span><span class="p">(</span><span class="n">q_0</span><span class="p">,</span> <span class="n">q_1</span><span class="p">,</span> <span class="n">q_2</span><span class="p">,</span> <span class="n">q_3</span><span class="p">)</span>
    
<span class="nb">print</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

<span class="c1"># [5.46991289990088, 6.313016781079707, 7.189835364530538, 8.668832766371658, 4.8028486314273, 3.346646443535637, -96.67286272722137, 4.161433444369266, 3.6539401768050603, 3.2220160316109103, 1.526193402980731]</span>

<span class="c1"># once v computed, we can calculate the optimal policy </span>
<span class="n">optPolicy</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">11</span>

<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">States</span><span class="p">:</span>       
    <span class="n">optPolicy</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">([</span><span class="nb">sum</span><span class="p">([</span><span class="n">trans</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">v</span><span class="p">[</span><span class="n">trans</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="k">for</span> <span class="n">trans</span> <span class="ow">in</span> <span class="n">P</span><span class="p">[</span><span class="n">s</span><span class="p">][</span><span class="n">a</span><span class="p">]])</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">Actions</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">optPolicy</span><span class="p">)</span>
<span class="c1"># [1, 1, 1, 0, 0, 3, 3, 0, 3, 3, 2]</span>
</pre></div>
</div>
</div>
<div class="section" id="value-iteration-in-gridworld-example">
<h2>Value Iteration in Gridworld Example<a class="headerlink" href="#value-iteration-in-gridworld-example" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>To solve the non-linear equations for <span class="math notranslate nohighlight">\(U^{*}(s)\)</span> we use an iterative approach.</p></li>
<li><p>Steps:</p>
<ul>
<li><p>Initialize estimates for the utilities of states with arbitrary values: <span class="math notranslate nohighlight">\(U(s) \leftarrow 0 \forall s \epsilon S\)</span></p></li>
<li><p>Next use the iteration step below which is also called <strong>Bellman Update</strong>:</p></li>
</ul>
</li>
</ul>
<div class="math notranslate nohighlight">
\[V_{t+1}(s) \leftarrow R(s) + \gamma \underset{a}{ \max} \left[ \sum_{s^{'}} P(s^{'}| s,a) U_t(s^{'}) \right] \forall s \epsilon S\]</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>This step is repeated and updated
</pre></div>
</div>
<ul class="simple">
<li><p>Let us apply this to the maze example.  Assume that <span class="math notranslate nohighlight">\(\gamma = 1\)</span></p></li>
</ul>
<p><img alt="val-iter-initial" src="../../../../../_images/val-iter-initial.png" /></p>
<p><em>Initialize value estimates to <span class="math notranslate nohighlight">\(0\)</span></em></p>
</div>
<div class="section" id="value-iteration">
<h2>Value Iteration<a class="headerlink" href="#value-iteration" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Next we want to apply <strong>Bellman Update</strong>:
$<span class="math notranslate nohighlight">\(V_{t+1}(s) \leftarrow R(s) + \gamma \max_{a} \left[\sum_{s^\prime} P(s^\prime | s,a)U_t(s^\prime) \right] \forall s \epsilon S\)</span>$</p></li>
<li><p>Since we are taking <span class="math notranslate nohighlight">\(\max\)</span> we only need to consider states whose next states have a positive utility value.</p></li>
<li><p>For the remaining states, the utility is equal to the immediate reward in the first iteration.</p></li>
</ul>
<p><img alt="States to consider for value iteration" src="../../../../../_images/val-iter-step1-states.png" /></p>
<div class="section" id="value-iteration-t-0">
<h3>Value Iteration (t=0)<a class="headerlink" href="#value-iteration-t-0" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[ V_{t+1}(s_{33})  =  R(s_{33}) + \gamma \max_a \left[\sum_{s^{'}} P(s^{'}| s_{33},a)U(s^{'}) \right] \forall s \in S \]</div>
<div class="math notranslate nohighlight">
\[ V_{t+1}(s_{33}) =  -0.04 + \max_a \left[ \sum_{s'}  P(s'| s_{33},\uparrow) U_t(s'), \sum_{s'}  P(s'| s_{33},\downarrow)U_t(s'), \sum_{s'}  P(s'| s_{33},\rightarrow) U_t(s'),  \sum_{s'}  P(s'| s_{33}, \leftarrow)U_t(s')  \right]\]</div>
<div class="math notranslate nohighlight">
\[V_{t+1}(s_{33})  =  -0.04 + \sum_{s^{'}}  P(s^{'}| s_{33},\rightarrow) U_t(s^\prime) \]</div>
<div class="math notranslate nohighlight">
\[V_{t+1}(s_{33}) = -0.04 + P(s_{43}|s_{33},\rightarrow)U(s_{43})+P(s_{33}|s_{33},\rightarrow)U(s_{33})+P(s_{32}|s_{33},\rightarrow)U_t(s_{32}) \]</div>
<div class="math notranslate nohighlight">
\[V_{t+1}(s_{33}) =   -0.04 + 0.8 \times 1 + 0.1 \times 0 + 0.1 \times 0 = 0.76 \]</div>
</div>
<div class="section" id="value-iteration-t-1">
<h3>Value Iteration (t=1)<a class="headerlink" href="#value-iteration-t-1" title="Permalink to this headline">¶</a></h3>
<p><img alt="val-iter-step2" src="../../../../../_images/val-iter-step2-initial.png" /></p>
<p><em>(A) Initial utility estimates for iteration 2. (B) States with next state positive utility</em></p>
<div class="math notranslate nohighlight">
\[V_{t+1}(s_{33}) =   -0.04 + P(s_{43}|s_{33},\rightarrow)U_t(s_{43})+P(s_{33}|s_{33},\rightarrow)U_t(s_{33}) +P(s_{32}|s_{33},\rightarrow)U_t(s_{32}) \]</div>
<div class="math notranslate nohighlight">
\[V_{t+1}(s_{33}) = -0.04 + 0.8 \times 1 + 0.1 \times 0.76 + 0.1 \times 0 = 0.836\]</div>
<div class="math notranslate nohighlight">
\[V_{t+1}(s_{23}) =  -0.04 + P(s_{33}|s_{23},\rightarrow)U_t(s_{23})+P(s_{23}|s_{23},\rightarrow)U_t(s_{23}) = -0.04 + 0.8 \times 0.76 = 0.568\]</div>
<div class="math notranslate nohighlight">
\[V_{t+1}(s_{32}) =  -0.04 + P(s_{33}|s_{32},\uparrow)U_t(s_{33})+P(s_{42}|s_{32},\uparrow)U_t(s_{42}) +P(s_{32}|s_{32},\uparrow)U_t(s_{32})\]</div>
<div class="math notranslate nohighlight">
\[V_{t+1}(s_{32}) = -0.04 + 0.8 \times 0.76 + 0.1 \times -1 + 0.1 \times 0= 0.468\]</div>
</div>
<div class="section" id="value-iteration-t-2">
<h3>Value Iteration (t=2)<a class="headerlink" href="#value-iteration-t-2" title="Permalink to this headline">¶</a></h3>
<p><img alt="val-iter-step3" src="../../../../../_images/val-iter-step3-initial.png" /></p>
<p><em>(A)Initial utility estimates for iteration 3. (B) States with next state positive utility</em></p>
<ul class="simple">
<li><p>Information propagates outward from terminal states
and eventually all states have correct value estimates</p></li>
<li><p>Notice that <span class="math notranslate nohighlight">\(s_{32}\)</span> has a lower utility compared to <span class="math notranslate nohighlight">\(s_{23}\)</span> due to the red oval state with negative reward next to <span class="math notranslate nohighlight">\(s_{32}\)</span></p></li>
</ul>
<p><img alt="Optimal Policy and Utilities for Maze" src="../../../../../_images/policy-utility.png" /></p>
</div>
<div class="section" id="value-iteration-convergence">
<h3>Value Iteration - Convergence<a class="headerlink" href="#value-iteration-convergence" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Rate of convergence depends on the maximum reward value and more importantly on the discount factor <span class="math notranslate nohighlight">\(\gamma\)</span>.</p></li>
<li><p>The policy that we get from coarse estimates is close to the optimal policy long before <span class="math notranslate nohighlight">\(U\)</span> has converged.</p></li>
<li><p>This means that after a reasonable number of iterations, we could use:
$<span class="math notranslate nohighlight">\(\pi(s) = \argmax_a \left[ \sum_{s^{'}} P(s^{'}| s,a)V_{est}(s^{'}) \right]\)</span>$</p></li>
<li><p>Note that this is a form of <strong>greedy</strong> policy.</p></li>
</ul>
<p><img alt="value-iter-convergence" src="../../../../../_images/value-iter-converge.PNG" /></p>
<p><em>Convergence of utility for the maze problem (Norvig chap 17)</em></p>
<ul class="simple">
<li><p>For the maze problem, convergence is reached within 5 to 10  iterations</p></li>
</ul>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./aiml-common/lectures/mdp/mdp-dp-algorithms/value-iteration"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../policy-improvement/_index.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Policy Improvement (Control)</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../../mdp-lab/recycling-robot/_index.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Finding the optimal policy of a recycling robot.</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Pantelis Monogioudis, Ph.D<br/>
    
        &copy; Copyright 2022.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>