Traceback (most recent call last):
  File "/home/runner/work/artificial-intelligence/artificial-intelligence/.venv/lib/python3.10/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/home/runner/work/artificial-intelligence/artificial-intelligence/.venv/lib/python3.10/site-packages/nbclient/client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/home/runner/work/artificial-intelligence/artificial-intelligence/.venv/lib/python3.10/site-packages/nbclient/util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/home/runner/work/artificial-intelligence/artificial-intelligence/.venv/lib/python3.10/site-packages/nbclient/util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/runner/work/artificial-intelligence/artificial-intelligence/.venv/lib/python3.10/site-packages/nbclient/client.py", line 663, in async_execute
    await self.async_execute_cell(
  File "/home/runner/work/artificial-intelligence/artificial-intelligence/.venv/lib/python3.10/site-packages/nbclient/client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/home/runner/work/artificial-intelligence/artificial-intelligence/.venv/lib/python3.10/site-packages/nbclient/client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
# Data augmentation and normalization for training
# Just normalization for validation
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
}

data_dir = 'data/hymenoptera_data'
image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),
                                          data_transforms[x])
                  for x in ['train', 'val']}
dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,
                                             shuffle=True, num_workers=4)
              for x in ['train', 'val']}
dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
class_names = image_datasets['train'].classes

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mFileNotFoundError[0m                         Traceback (most recent call last)
Cell [0;32mIn[3], line 19[0m
[1;32m      3[0m data_transforms [38;5;241m=[39m {
[1;32m      4[0m     [38;5;124m'[39m[38;5;124mtrain[39m[38;5;124m'[39m: transforms[38;5;241m.[39mCompose([
[1;32m      5[0m         transforms[38;5;241m.[39mRandomResizedCrop([38;5;241m224[39m),
[0;32m   (...)[0m
[1;32m     15[0m     ]),
[1;32m     16[0m }
[1;32m     18[0m data_dir [38;5;241m=[39m [38;5;124m'[39m[38;5;124mdata/hymenoptera_data[39m[38;5;124m'[39m
[0;32m---> 19[0m image_datasets [38;5;241m=[39m {x: datasets[38;5;241m.[39mImageFolder(os[38;5;241m.[39mpath[38;5;241m.[39mjoin(data_dir, x),
[1;32m     20[0m                                           data_transforms[x])
[1;32m     21[0m                   [38;5;28;01mfor[39;00m x [38;5;129;01min[39;00m [[38;5;124m'[39m[38;5;124mtrain[39m[38;5;124m'[39m, [38;5;124m'[39m[38;5;124mval[39m[38;5;124m'[39m]}
[1;32m     22[0m dataloaders [38;5;241m=[39m {x: torch[38;5;241m.[39mutils[38;5;241m.[39mdata[38;5;241m.[39mDataLoader(image_datasets[x], batch_size[38;5;241m=[39m[38;5;241m4[39m,
[1;32m     23[0m                                              shuffle[38;5;241m=[39m[38;5;28;01mTrue[39;00m, num_workers[38;5;241m=[39m[38;5;241m4[39m)
[1;32m     24[0m               [38;5;28;01mfor[39;00m x [38;5;129;01min[39;00m [[38;5;124m'[39m[38;5;124mtrain[39m[38;5;124m'[39m, [38;5;124m'[39m[38;5;124mval[39m[38;5;124m'[39m]}
[1;32m     25[0m dataset_sizes [38;5;241m=[39m {x: [38;5;28mlen[39m(image_datasets[x]) [38;5;28;01mfor[39;00m x [38;5;129;01min[39;00m [[38;5;124m'[39m[38;5;124mtrain[39m[38;5;124m'[39m, [38;5;124m'[39m[38;5;124mval[39m[38;5;124m'[39m]}

Cell [0;32mIn[3], line 19[0m, in [0;36m<dictcomp>[0;34m(.0)[0m
[1;32m      3[0m data_transforms [38;5;241m=[39m {
[1;32m      4[0m     [38;5;124m'[39m[38;5;124mtrain[39m[38;5;124m'[39m: transforms[38;5;241m.[39mCompose([
[1;32m      5[0m         transforms[38;5;241m.[39mRandomResizedCrop([38;5;241m224[39m),
[0;32m   (...)[0m
[1;32m     15[0m     ]),
[1;32m     16[0m }
[1;32m     18[0m data_dir [38;5;241m=[39m [38;5;124m'[39m[38;5;124mdata/hymenoptera_data[39m[38;5;124m'[39m
[0;32m---> 19[0m image_datasets [38;5;241m=[39m {x: [43mdatasets[49m[38;5;241;43m.[39;49m[43mImageFolder[49m[43m([49m[43mos[49m[38;5;241;43m.[39;49m[43mpath[49m[38;5;241;43m.[39;49m[43mjoin[49m[43m([49m[43mdata_dir[49m[43m,[49m[43m [49m[43mx[49m[43m)[49m[43m,[49m
[1;32m     20[0m [43m                                          [49m[43mdata_transforms[49m[43m[[49m[43mx[49m[43m][49m[43m)[49m
[1;32m     21[0m                   [38;5;28;01mfor[39;00m x [38;5;129;01min[39;00m [[38;5;124m'[39m[38;5;124mtrain[39m[38;5;124m'[39m, [38;5;124m'[39m[38;5;124mval[39m[38;5;124m'[39m]}
[1;32m     22[0m dataloaders [38;5;241m=[39m {x: torch[38;5;241m.[39mutils[38;5;241m.[39mdata[38;5;241m.[39mDataLoader(image_datasets[x], batch_size[38;5;241m=[39m[38;5;241m4[39m,
[1;32m     23[0m                                              shuffle[38;5;241m=[39m[38;5;28;01mTrue[39;00m, num_workers[38;5;241m=[39m[38;5;241m4[39m)
[1;32m     24[0m               [38;5;28;01mfor[39;00m x [38;5;129;01min[39;00m [[38;5;124m'[39m[38;5;124mtrain[39m[38;5;124m'[39m, [38;5;124m'[39m[38;5;124mval[39m[38;5;124m'[39m]}
[1;32m     25[0m dataset_sizes [38;5;241m=[39m {x: [38;5;28mlen[39m(image_datasets[x]) [38;5;28;01mfor[39;00m x [38;5;129;01min[39;00m [[38;5;124m'[39m[38;5;124mtrain[39m[38;5;124m'[39m, [38;5;124m'[39m[38;5;124mval[39m[38;5;124m'[39m]}

File [0;32m~/work/artificial-intelligence/artificial-intelligence/.venv/lib/python3.10/site-packages/torchvision/datasets/folder.py:309[0m, in [0;36mImageFolder.__init__[0;34m(self, root, transform, target_transform, loader, is_valid_file)[0m
[1;32m    301[0m [38;5;28;01mdef[39;00m [38;5;21m__init__[39m(
[1;32m    302[0m     [38;5;28mself[39m,
[1;32m    303[0m     root: [38;5;28mstr[39m,
[0;32m   (...)[0m
[1;32m    307[0m     is_valid_file: Optional[Callable[[[38;5;28mstr[39m], [38;5;28mbool[39m]] [38;5;241m=[39m [38;5;28;01mNone[39;00m,
[1;32m    308[0m ):
[0;32m--> 309[0m     [38;5;28;43msuper[39;49m[43m([49m[43m)[49m[38;5;241;43m.[39;49m[38;5;21;43m__init__[39;49m[43m([49m
[1;32m    310[0m [43m        [49m[43mroot[49m[43m,[49m
[1;32m    311[0m [43m        [49m[43mloader[49m[43m,[49m
[1;32m    312[0m [43m        [49m[43mIMG_EXTENSIONS[49m[43m [49m[38;5;28;43;01mif[39;49;00m[43m [49m[43mis_valid_file[49m[43m [49m[38;5;129;43;01mis[39;49;00m[43m [49m[38;5;28;43;01mNone[39;49;00m[43m [49m[38;5;28;43;01melse[39;49;00m[43m [49m[38;5;28;43;01mNone[39;49;00m[43m,[49m
[1;32m    313[0m [43m        [49m[43mtransform[49m[38;5;241;43m=[39;49m[43mtransform[49m[43m,[49m
[1;32m    314[0m [43m        [49m[43mtarget_transform[49m[38;5;241;43m=[39;49m[43mtarget_transform[49m[43m,[49m
[1;32m    315[0m [43m        [49m[43mis_valid_file[49m[38;5;241;43m=[39;49m[43mis_valid_file[49m[43m,[49m
[1;32m    316[0m [43m    [49m[43m)[49m
[1;32m    317[0m     [38;5;28mself[39m[38;5;241m.[39mimgs [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39msamples

File [0;32m~/work/artificial-intelligence/artificial-intelligence/.venv/lib/python3.10/site-packages/torchvision/datasets/folder.py:144[0m, in [0;36mDatasetFolder.__init__[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)[0m
[1;32m    134[0m [38;5;28;01mdef[39;00m [38;5;21m__init__[39m(
[1;32m    135[0m     [38;5;28mself[39m,
[1;32m    136[0m     root: [38;5;28mstr[39m,
[0;32m   (...)[0m
[1;32m    141[0m     is_valid_file: Optional[Callable[[[38;5;28mstr[39m], [38;5;28mbool[39m]] [38;5;241m=[39m [38;5;28;01mNone[39;00m,
[1;32m    142[0m ) [38;5;241m-[39m[38;5;241m>[39m [38;5;28;01mNone[39;00m:
[1;32m    143[0m     [38;5;28msuper[39m()[38;5;241m.[39m[38;5;21m__init__[39m(root, transform[38;5;241m=[39mtransform, target_transform[38;5;241m=[39mtarget_transform)
[0;32m--> 144[0m     classes, class_to_idx [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mfind_classes[49m[43m([49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mroot[49m[43m)[49m
[1;32m    145[0m     samples [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mmake_dataset([38;5;28mself[39m[38;5;241m.[39mroot, class_to_idx, extensions, is_valid_file)
[1;32m    147[0m     [38;5;28mself[39m[38;5;241m.[39mloader [38;5;241m=[39m loader

File [0;32m~/work/artificial-intelligence/artificial-intelligence/.venv/lib/python3.10/site-packages/torchvision/datasets/folder.py:218[0m, in [0;36mDatasetFolder.find_classes[0;34m(self, directory)[0m
[1;32m    191[0m [38;5;28;01mdef[39;00m [38;5;21mfind_classes[39m([38;5;28mself[39m, directory: [38;5;28mstr[39m) [38;5;241m-[39m[38;5;241m>[39m Tuple[List[[38;5;28mstr[39m], Dict[[38;5;28mstr[39m, [38;5;28mint[39m]]:
[1;32m    192[0m [38;5;250m    [39m[38;5;124;03m"""Find the class folders in a dataset structured as follows::[39;00m
[1;32m    193[0m 
[1;32m    194[0m [38;5;124;03m        directory/[39;00m
[0;32m   (...)[0m
[1;32m    216[0m [38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.[39;00m
[1;32m    217[0m [38;5;124;03m    """[39;00m
[0;32m--> 218[0m     [38;5;28;01mreturn[39;00m [43mfind_classes[49m[43m([49m[43mdirectory[49m[43m)[49m

File [0;32m~/work/artificial-intelligence/artificial-intelligence/.venv/lib/python3.10/site-packages/torchvision/datasets/folder.py:40[0m, in [0;36mfind_classes[0;34m(directory)[0m
[1;32m     35[0m [38;5;28;01mdef[39;00m [38;5;21mfind_classes[39m(directory: [38;5;28mstr[39m) [38;5;241m-[39m[38;5;241m>[39m Tuple[List[[38;5;28mstr[39m], Dict[[38;5;28mstr[39m, [38;5;28mint[39m]]:
[1;32m     36[0m [38;5;250m    [39m[38;5;124;03m"""Finds the class folders in a dataset.[39;00m
[1;32m     37[0m 
[1;32m     38[0m [38;5;124;03m    See :class:`DatasetFolder` for details.[39;00m
[1;32m     39[0m [38;5;124;03m    """[39;00m
[0;32m---> 40[0m     classes [38;5;241m=[39m [38;5;28msorted[39m(entry[38;5;241m.[39mname [38;5;28;01mfor[39;00m entry [38;5;129;01min[39;00m [43mos[49m[38;5;241;43m.[39;49m[43mscandir[49m[43m([49m[43mdirectory[49m[43m)[49m [38;5;28;01mif[39;00m entry[38;5;241m.[39mis_dir())
[1;32m     41[0m     [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m classes:
[1;32m     42[0m         [38;5;28;01mraise[39;00m [38;5;167;01mFileNotFoundError[39;00m([38;5;124mf[39m[38;5;124m"[39m[38;5;124mCouldn[39m[38;5;124m'[39m[38;5;124mt find any class folder in [39m[38;5;132;01m{[39;00mdirectory[38;5;132;01m}[39;00m[38;5;124m.[39m[38;5;124m"[39m)

[0;31mFileNotFoundError[0m: [Errno 2] No such file or directory: 'data/hymenoptera_data/train'
FileNotFoundError: [Errno 2] No such file or directory: 'data/hymenoptera_data/train'

